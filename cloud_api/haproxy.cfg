# HAProxy Configuration for YouTube Size Extension Cloud API
# High-performance load balancing with health checks and monitoring
#
# Features:
# - Layer 7 (HTTP) load balancing
# - Active health checks with automatic failover
# - Round-robin distribution with least-conn fallback
# - Connection pooling and HTTP/1.1 keepalive
# - Statistics dashboard on :8404
# - Request ID injection for distributed tracing
# - Rate limiting and DDoS protection

#---------------------------------------------------------------------
# Global settings
#---------------------------------------------------------------------
global
    # Runtime user/group
    user haproxy
    group haproxy
    
    # Max connections (tune based on system resources)
    maxconn 4096
    
    # Logging
    log /dev/log local0
    log /dev/log local1 notice
    
    # Performance tuning
    nbproc 1
    nbthread 4
    cpu-map auto:1/1-4 0-3
    
    # SSL/TLS
    ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256
    ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets
    
    # Stats socket for monitoring
    stats socket /var/run/haproxy.sock mode 660 level admin expose-fd listeners
    stats timeout 30s

#---------------------------------------------------------------------
# Common defaults
#---------------------------------------------------------------------
defaults
    mode http
    log global
    option httplog
    option dontlognull
    option http-server-close
    option forwardfor except 127.0.0.0/8
    option redispatch
    
    # Timeouts
    timeout connect 5s
    timeout client 30s
    timeout server 35s  # API timeout (25s) + buffer (10s)
    timeout http-request 10s
    timeout http-keep-alive 2s
    timeout queue 10s
    timeout check 5s
    
    # Connection limits
    maxconn 2000
    
    # Retry behavior
    retries 2
    retry-on conn-failure empty-response response-timeout 502 503
    
    # Error pages
    errorfile 400 /etc/haproxy/errors/400.http
    errorfile 403 /etc/haproxy/errors/403.http
    errorfile 408 /etc/haproxy/errors/408.http
    errorfile 500 /etc/haproxy/errors/500.http
    errorfile 502 /etc/haproxy/errors/502.http
    errorfile 503 /etc/haproxy/errors/503.http
    errorfile 504 /etc/haproxy/errors/504.http

#---------------------------------------------------------------------
# Statistics dashboard
#---------------------------------------------------------------------
frontend stats
    bind *:8404
    stats enable
    stats uri /
    stats refresh 5s
    stats show-legends
    stats show-node
    stats auth admin:changeme  # CHANGE THIS PASSWORD!
    stats admin if TRUE

#---------------------------------------------------------------------
# HTTP Frontend (port 80)
#---------------------------------------------------------------------
frontend http_front
    bind *:80
    
    # Logging with timing information
    option httplog
    
    # Capture request ID for distributed tracing
    http-request capture req.hdr(X-Request-ID) len 64
    
    # Generate request ID if not provided
    http-request set-var(txn.req_id) req.hdr(X-Request-ID)
    http-request set-header X-Request-ID %[var(txn.req_id)] if { var(txn.req_id) -m found }
    http-request set-header X-Request-ID %[uuid()] unless { var(txn.req_id) -m found }
    
    # Capture original client IP
    http-request set-header X-Real-IP %[src]
    
    # Rate limiting using stick tables
    # Track by source IP: max 20 requests per minute
    stick-table type ip size 100k expire 60s store http_req_rate(60s)
    http-request track-sc0 src
    http-request deny deny_status 429 if { sc_http_req_rate(0) gt 20 }
    
    # ACLs for different paths
    acl is_health path /health
    acl is_health_redis path /health/redis
    acl is_api path_beg /api/
    acl is_root path /
    
    # Health checks bypass rate limiting
    http-request set-var(txn.skip_rate_limit) int(1) if is_health or is_health_redis
    
    # Route to appropriate backend
    use_backend health_check if is_health or is_health_redis
    use_backend api_backend if is_api
    default_backend api_backend

#---------------------------------------------------------------------
# HTTPS Frontend (port 443) - Optional
#---------------------------------------------------------------------
# Uncomment and configure if you want HAProxy to handle SSL termination
#
# frontend https_front
#     bind *:443 ssl crt /etc/haproxy/ssl/api.example.com.pem
#     
#     # Security headers
#     http-response set-header Strict-Transport-Security "max-age=31536000; includeSubDomains"
#     http-response set-header X-Frame-Options "SAMEORIGIN"
#     http-response set-header X-Content-Type-Options "nosniff"
#     http-response set-header X-XSS-Protection "1; mode=block"
#     
#     # Same ACLs and routing as HTTP frontend
#     # (copy configuration from http_front)
#     use_backend health_check if is_health or is_health_redis
#     use_backend api_backend if is_api
#     default_backend api_backend

#---------------------------------------------------------------------
# Backend: Health Check (no rate limiting)
#---------------------------------------------------------------------
backend health_check
    balance roundrobin
    
    # Health check configuration
    option httpchk GET /health
    http-check expect status 200
    
    # Connection pooling
    http-reuse safe
    
    # Backend servers
    server api1 api1.example.com:3000 check inter 10s fall 3 rise 2
    server api2 api2.example.com:3000 check inter 10s fall 3 rise 2
    server api3 api3.example.com:3000 check inter 10s fall 3 rise 2 backup

#---------------------------------------------------------------------
# Backend: API (with rate limiting and full checks)
#---------------------------------------------------------------------
backend api_backend
    # Load balancing algorithm
    # Options: roundrobin, leastconn, source (IP hash), uri (URL hash)
    balance leastconn
    
    # Health check configuration
    option httpchk GET /health
    http-check expect status 200
    
    # HTTP/1.1 with keepalive
    option http-server-close
    http-reuse safe
    
    # Compression
    compression algo gzip
    compression type application/json text/plain
    
    # Response headers
    http-response set-header X-Served-By %[env(HOSTNAME)]
    http-response add-header X-Request-ID %[req.hdr(X-Request-ID)]
    
    # Backend servers
    # Format: server <name> <address>:<port> [options]
    # Options:
    #   check = enable health checks
    #   inter = health check interval (default: 2s)
    #   fall = failures before marking down (default: 3)
    #   rise = successes before marking up (default: 2)
    #   maxconn = max connections to this server
    #   weight = load distribution weight (default: 1)
    #   backup = only use if all primary servers are down
    
    # Primary API instance 1
    server api1 api1.example.com:3000 check inter 10s fall 3 rise 2 maxconn 100 weight 100
    
    # Primary API instance 2
    server api2 api2.example.com:3000 check inter 10s fall 3 rise 2 maxconn 100 weight 100
    
    # Backup API instance 3
    server api3 api3.example.com:3000 check inter 10s fall 3 rise 2 maxconn 100 weight 100 backup
    
    # Cookie-based session persistence (optional)
    # Uncomment if you need sticky sessions
    # cookie SERVERID insert indirect nocache
    # server api1 ... cookie api1
    # server api2 ... cookie api2

#---------------------------------------------------------------------
# Notes for Production Deployment:
#---------------------------------------------------------------------
# 1. Replace api1/2/3.example.com with your actual server addresses
# 2. Update stats authentication password
# 3. Configure SSL certificates if using HTTPS
# 4. Adjust timeouts based on your API response times
# 5. Tune maxconn based on expected traffic and server capacity
# 6. Consider enabling cookie-based persistence if needed
# 7. Monitor the stats dashboard at http://<haproxy-host>:8404
# 8. Ensure /etc/haproxy/errors/ directory contains error pages
# 9. Configure logging to syslog or file
# 10. Set up monitoring alerts for backend server health
